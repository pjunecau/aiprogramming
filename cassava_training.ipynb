{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport random\nimport os\nimport cv2\nimport sys\nfrom pylab import rcParams\nfrom PIL import Image\nwarnings.filterwarnings('ignore')\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Input, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.applications import VGG16, InceptionV3, Xception, EfficientNetB3\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\nfrom sklearn.model_selection import StratifiedShuffleSplit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"policy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_policy(policy) #shortens training time by 2x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\ndf_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[\"label\"] = df_train[\"label\"].astype(str) #convert to str as we want to use Categorical Cross Entropy (CCE) later on\ndf_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"sns.set_style(\"whitegrid\")\nplt.figure(figsize=(10,8))\nsns.countplot(df_train[\"label\"], edgecolor=\"black\", palette=\"mako\", order=['0','1','2','3','4'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Label 0: Cassava Bacterial Blight (CBB)","metadata":{}},{"cell_type":"code","source":"path = \"../input/cassava-leaf-disease-classification/train_images/\"\ndf0 = df_train[df_train[\"label\"] == \"0\"]\nfiles = df0[\"image_id\"].sample(3).tolist()\n\nplt.figure(figsize=(15,5))\nindex = 0\nfor file in files:\n    image = Image.open(path + file)\n    plt.subplot(1, 3, index + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    index += 1\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Label 1: Cassava Brown Streak Disease (CBSD)","metadata":{}},{"cell_type":"code","source":"df1 = df_train[df_train[\"label\"] == \"1\"]\nfiles = df1[\"image_id\"].sample(3).tolist()\n\nplt.figure(figsize=(15,5))\nindex = 0\nfor file in files:\n    image = Image.open(path + file)\n    plt.subplot(1, 3, index + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    index += 1\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Label 2: Cassava Green Mottle (CGM)","metadata":{}},{"cell_type":"code","source":"df2 = df_train[df_train[\"label\"] == \"2\"]\nfiles = df2[\"image_id\"].sample(3).tolist()\n\nplt.figure(figsize=(15,5))\nindex = 0\nfor file in files:\n    image = Image.open(path + file)\n    plt.subplot(1, 3, index + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    index += 1\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Label 3: Cassava Mosiac Disease (CMD)","metadata":{}},{"cell_type":"code","source":"df3 = df_train[df_train[\"label\"] == \"3\"]\nfiles = df3[\"image_id\"].sample(3).tolist()\n\nplt.figure(figsize=(15,5))\nindex = 0\nfor file in files:\n    image = Image.open(path + file)\n    plt.subplot(1, 3, index + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    index += 1\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Label 4: Healthy","metadata":{}},{"cell_type":"code","source":"df4 = df_train[df_train[\"label\"] == \"4\"]\nfiles = df4[\"image_id\"].sample(3).tolist()\n\nplt.figure(figsize=(15,5))\nindex = 0\nfor file in files:\n    image = Image.open(path + file)\n    plt.subplot(1, 3, index + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    index += 1\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image Augmentation (Tensorflow)","metadata":{}},{"cell_type":"code","source":"batch_size=16\nimage_size=300\n\ninput_shape = (image_size, image_size, 3)\ntarget_size = (image_size, image_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_augmentation = tf.keras.Sequential(\n    [\n        tf.keras.layers.experimental.preprocessing.RandomCrop(image_size, image_size),\n        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n        tf.keras.layers.experimental.preprocessing.RandomRotation(0.25),\n        tf.keras.layers.experimental.preprocessing.RandomZoom((-0.25, 0.25), (-0.25, 0.25)),\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"../input/cassava-leaf-disease-classification/train_images/\"\nfiles = df_train[\"image_id\"].tolist()\nfile = random.choice(files)\nimage = Image.open(path + file)\nplt.imshow(image)\nplt.axis(\"off\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = tf.expand_dims(np.array(image), 0)\n\nplt.figure(figsize=(14, 14))\nfor i in range(9):\n    augmented_image = img_augmentation(image)\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(augmented_image[0])\n    plt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image Augmentation (Albumentations)","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/mjkvaak/ImageDataAugmentor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ImageDataAugmentor.image_data_augmentor import *\nimport albumentations as A\n\ntrain_augmentations = A.Compose([\n            A.RandomCrop(image_size, image_size, p=1),\n            A.CoarseDropout(p=0.5),\n            A.Cutout(p=0.5),\n            A.Flip(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.HueSaturationValue(p=0.5, hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n            A.RandomBrightnessContrast(p=0.5, brightness_limit=(-0.2,0.2), contrast_limit=(-0.2, 0.2)),\n            A.ToFloat()\n            ], p=1)\n\nval_augmentations = A.Compose([\n                A.CenterCrop(image_size, image_size, p=1),\n                A.ToFloat()\n                ], p=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def TFDataGenerator(train_set, val_set):\n    \n    train_generator = ImageDataAugmentor(augment=train_augmentations)\n    val_generator = ImageDataAugmentor(augment=val_augmentations)\n    \n    train_datagen = train_generator.flow_from_dataframe(\n                  dataframe = train_set,\n                  directory='../input/cassava-leaf-disease-classification/train_images',\n                  x_col='image_id',\n                  y_col='label',\n                  target_size=target_size,\n                  batch_size=batch_size,\n                  shuffle=True,\n                  class_mode='categorical',\n                  seed=2020)\n\n    val_datagen = val_generator.flow_from_dataframe(\n                dataframe = val_set,\n                directory='../input/cassava-leaf-disease-classification/train_images',\n                x_col='image_id',\n                y_col='label',\n                target_size=target_size,\n                batch_size=batch_size,\n                shuffle=False,\n                class_mode='categorical',\n                seed=2020)\n    \n    return train_datagen, val_datagen","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = df_train.iloc[:10]\nval_set = df_train.iloc[-10:]\n\ntrain_datagen, val_datagen = TFDataGenerator(train_set, val_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images, _ = next(train_datagen)\n\nplt.figure(figsize=(14, 14))\nfor i in range(9):\n    image = train_images[i]\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_images, _ = next(val_datagen)\n\nplt.figure(figsize=(14, 14))\nfor i in range(9):\n    image = val_images[i]\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Building and Selection","metadata":{}},{"cell_type":"code","source":"def create_cnn():\n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape),\n        tf.keras.layers.MaxPooling2D(2, 2),\n        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n        tf.keras.layers.MaxPooling2D(2, 2),\n        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n        tf.keras.layers.MaxPooling2D(2, 2),\n        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n        tf.keras.layers.MaxPooling2D(2, 2),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Dense(5, activation='softmax')\n    ])\n\n    # Compile\n    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=10e-5), metrics=['accuracy'])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_vgg16():\n    \n    model = Sequential()\n    model.add(VGG16(input_shape = input_shape, include_top = False, weights = 'imagenet'))\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(512, activation = 'relu', bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001)))\n    model.add(Dropout(0.5))\n    model.add(Dense(5, activation = 'softmax',dtype='float32')) #this is very important to use mixed_precision\n\n    loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True,\n                                               label_smoothing=0.2,\n                                               name='categorical_crossentropy' )\n    \n        # Compile\n    model.compile(loss=loss, optimizer=keras.optimizers.Adam(lr=1e-3), metrics=['accuracy'])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_Inception():\n    base_model = InceptionV3(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n\n    # Rebuild top\n    inputs = Input(shape=input_shape)\n\n    model = base_model(inputs)\n    pooling = GlobalAveragePooling2D()(model)\n    dropout = Dropout(0.2)(pooling)\n\n    outputs = Dense(5, activation=\"softmax\", name=\"dense\", dtype='float32')(dropout)\n\n    # Compile\n    inception = Model(inputs=inputs, outputs=outputs)\n    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2, from_logits=True)\n\n    inception.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n    return inception","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_Xception():\n    base_model = Xception(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n\n    # Rebuild top\n    inputs = Input(shape=input_shape)\n\n    model = base_model(inputs)\n    pooling = GlobalAveragePooling2D()(model)\n    dropout = Dropout(0.2)(pooling)\n\n    outputs = Dense(5, activation=\"softmax\", name=\"dense\", dtype='float32')(dropout)\n\n    # Compile\n    xception = Model(inputs=inputs, outputs=outputs)\n    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2, from_logits=True)\n\n    xception.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n    return xception","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_EfficientNetB3():\n    \n    model = Sequential()\n    model.add(EfficientNetB3(input_shape = input_shape, include_top = False, weights = 'imagenet'))\n    model.add(GlobalAveragePooling2D())\n    #model.add(Dense(64, activation = 'relu', bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001)))\n    model.add(Dropout(0.2))\n    model.add(Dense(5, activation = 'softmax',dtype='float32'))\n\n    loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True,\n                                               label_smoothing=0.2,\n                                               name='categorical_crossentropy' )\n    \n    # Compile\n    model.compile(loss=loss, optimizer=keras.optimizers.Adam(lr=1e-3), metrics=['accuracy'])\n    return model ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training with Stratified K-Fold Cross Validation","metadata":{}},{"cell_type":"code","source":"def plot_result(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    epochs = range(len(acc))\n\n    plt.figure(figsize=(15, 5))\n    plt.plot(epochs, acc, 'b*-', label='Training accuracy')\n    plt.plot(epochs, val_acc, 'r*-', label='Validation accuracy')\n    plt.grid()\n    plt.title('Training and validation accuracy')\n    plt.ylabel(\"Accuracy\")\n    plt.xlabel(\"Epochs\")\n    plt.legend()\n    plt.figure()\n    plt.show()\n\n    plt.figure(figsize=(15, 5))\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    plt.plot(epochs, loss, 'b*-', label='Training Loss')\n    plt.plot(epochs, val_loss, 'r*-', label='Validation Loss')\n    plt.grid()\n    plt.title('Training and validation loss')\n    plt.ylabel(\"Loss\")\n    plt.xlabel(\"Epochs\")\n    plt.legend()\n    plt.figure()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fold_number = 0\n# n_splits = 2\n# epochs = 8\n\n# tf.keras.backend.clear_session()\n# sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.1, random_state=2020)\n# for train_index, val_index in sss.split(df_train[\"image_id\"], df_train[\"label\"]):\n#     train_set = df_train.loc[train_index]\n#     val_set = df_train.loc[val_index]\n#     train_datagen, val_datagen = TFDataGenerator(train_set, val_set)\n#     model = create_cnn()\n#     print(\"Training fold no.: \" + str(fold_number+1))\n\n#     model_name = \"cnn\"\n#     fold_name = \"fold.h5\"\n#     filepath = model_name + str(fold_number+1) + fold_name\n#     callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.2),\n#                  EarlyStopping(monitor='val_loss', patience=3),\n#                  ModelCheckpoint(filepath=filepath, monitor='val_loss', save_best_only=True)]\n\n#     history1 = model.fit(train_datagen, epochs=epochs, validation_data=val_datagen, callbacks=callbacks)\n#     fold_number += 1\n#     if fold_number == n_splits:\n#         print(\"Training finished!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_result(history1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fold_number = 0\n# n_spilts = 2\n# epochs = 8\n\n# tf.keras.backend.clear_session()\n# sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.1, random_state=2020)\n# for train_index, val_index in sss.split(df_train[\"image_id\"], df_train[\"label\"]):\n#     train_set = df_train.loc[train_index]\n#     val_set = df_train.loc[val_index]\n#     train_datagen, val_datagen = TFDataGenerator(train_set, val_set)\n#     model = create_vgg16()\n#     print(\"Training fold no.: \" + str(fold_number+1))\n\n#     model_name = \"vgg16\"\n#     fold_name = \"fold.h5\"\n#     filepath = model_name + str(fold_number+1) + fold_name\n#     callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.2),\n#                  EarlyStopping(monitor='val_loss', patience=3),\n#                  ModelCheckpoint(filepath=filepath, monitor='val_loss', save_best_only=True)]\n\n#     history2 = model.fit(train_datagen, epochs=epochs, validation_data=val_datagen, callbacks=callbacks)\n#     fold_number += 1\n#     if fold_number == n_splits:\n#         print(\"Training finished!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_result(history2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fold_number = 0\n# n_splits = 2\n# epochs = 8\n\n# tf.keras.backend.clear_session()\n# sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.1, random_state=2020)\n# for train_index, val_index in sss.split(df_train[\"image_id\"], df_train[\"label\"]):\n#     train_set = df_train.loc[train_index]\n#     val_set = df_train.loc[val_index]\n#     train_datagen, val_datagen = TFDataGenerator(train_set, val_set)\n#     model = create_Inception()\n#     print(\"Training fold no.: \" + str(fold_number+1))\n\n#     model_name = \"inception \"\n#     fold_name = \"fold.h5\"\n#     filepath = model_name + str(fold_number+1) + fold_name\n#     callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.2),\n#                  EarlyStopping(monitor='val_loss', patience=3),\n#                  ModelCheckpoint(filepath=filepath, monitor='val_loss', save_best_only=True)]\n\n#     history3 = model.fit(train_datagen, epochs=epochs, validation_data=val_datagen, callbacks=callbacks)\n#     fold_number += 1\n#     if fold_number == n_splits:\n#         print(\"Training finished!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_result(history3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fold_number = 0\n# n_splits = 2\n# epochs = 8\n\n# tf.keras.backend.clear_session()\n# sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.1, random_state=2020)\n# for train_index, val_index in sss.split(df_train[\"image_id\"], df_train[\"label\"]):\n#     train_set = df_train.loc[train_index]\n#     val_set = df_train.loc[val_index]\n#     train_datagen, val_datagen = TFDataGenerator(train_set, val_set)\n#     model = create_Xception()\n#     print(\"Training fold no.: \" + str(fold_number+1))\n\n#     model_name = \"xception \"\n#     fold_name = \"fold.h5\"\n#     filepath = model_name + str(fold_number+1) + fold_name\n#     callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.2),\n#                  EarlyStopping(monitor='val_loss', patience=3),\n#                  ModelCheckpoint(filepath=filepath, monitor='val_loss', save_best_only=True)]\n\n#     history4 = model.fit(train_datagen, epochs=epochs, validation_data=val_datagen, callbacks=callbacks)\n#     fold_number += 1\n#     if fold_number == n_splits:\n#         print(\"Training finished!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_result(history4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_number = 0\nn_splits = 2\nepochs = 8\n\ntf.keras.backend.clear_session()\nsss = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.1, random_state=2020)\nfor train_index, val_index in sss.split(df_train[\"image_id\"], df_train[\"label\"]):\n    train_set = df_train.loc[train_index]\n    val_set = df_train.loc[val_index]\n    train_datagen, val_datagen = TFDataGenerator(train_set, val_set)\n    model = create_EfficientNetB3()\n    print(\"Training fold no.: \" + str(fold_number+1))\n\n    model_name = \"efficientnetb3\"\n    fold_name = \"fold.h5\"\n    filepath = model_name + str(fold_number+1) + fold_name\n    callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.2),\n                 EarlyStopping(monitor='val_loss', patience=3),\n                 ModelCheckpoint(filepath=filepath, monitor='val_loss', save_best_only=True)]\n\n    history5 = model.fit(train_datagen, epochs=epochs, validation_data=val_datagen, callbacks=callbacks)\n    fold_number += 1\n    if fold_number == n_splits:\n        print(\"Training finished!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_result(history5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Ensembling and Inference","metadata":{}},{"cell_type":"code","source":"# models = []\n# for i in range(n_splits):\n#     inception = load_model(\"./inception \" + str(i+1) + \"fold.h5\")\n#     models.append(inception)\n    \n# for i in range(n_splits):\n#     efficientnetb3 = load_model(\"./efficientnetb3 \" + str(i+1) + \"fold.h5\")\n#     models.append(efficientnetb3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ss = pd.read_csv(os.path.join('../input/cassava-leaf-disease-classification', \"sample_submission.csv\"))\n# preds = []\n# results = []\n\n# for image_id in ss.image_id:\n#     image = Image.open(os.path.join('../input/cassava-leaf-disease-classification', \"test_images\", image_id))\n#     image = image.resize((image_size, image_size))\n#     image = np.expand_dims(image, axis = 0)\n#     for model in models:\n#         preds.append(np.argmax(model.predict(image)))\n#     res = max(set(preds), key = preds.count)\n#     results.append(res)\n\n# ss['label'] = results\n# ss.to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}